{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import codecs\n",
    "from itertools import izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Converts indices to words \n",
    "def convert_to_words(indices):\n",
    "    return (' '.join([word_dict[ind] for ind in indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = '../data/MovieTriple/'\n",
    "\n",
    "# Loading all the possible files into memory\n",
    "with open(directory + 'Training.triples.pkl') as f:\n",
    "    train_set = pickle.load(f)\n",
    "    \n",
    "with open(directory + 'Validation.triples.pkl') as f:\n",
    "    valid_set = pickle.load(f)\n",
    "    \n",
    "with open(directory + 'Test.triples.pkl') as f:\n",
    "    test_set = pickle.load(f)\n",
    "\n",
    "with open(directory + 'Training.dict.pkl') as f:\n",
    "    word_mappings = pickle.load(f)\n",
    "    \n",
    "with open(directory + 'Word2Vec_WordEmb.pkl') as f:\n",
    "    emb_wordvec = pickle.load(f)\n",
    "    \n",
    "with open(directory + 'MT_WordEmb.pkl') as f:\n",
    "    emb_mt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('raining', 4959, 53, 48),\n",
       " ('writings', 9977, 18, 15),\n",
       " ('yellow', 2155, 175, 142),\n",
       " ('four', 341, 2299, 2081),\n",
       " ('prices', 5660, 43, 40)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training.dict.pkl: Dictionary with 10000 words extracted from the training \n",
    "# set (Training_Shuffled_Dataset.txt). These terms represent 97.97% of the \n",
    "# entire training set.\n",
    "\n",
    "# Not entirely sure what the other two numbers reprsent in the word index table\n",
    "# Maybe corresponds to the counts in train... or something?\n",
    "\n",
    "word_mappings[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "# Move through the list of words and indices and generate a dictionary\n",
    "# matching the indices to words\n",
    "\n",
    "# indices -> word\n",
    "indices_to_word = {}\n",
    "for word_ex in word_mappings: \n",
    "    indices_to_word[word_ex[1]] = word_ex[0]\n",
    "    \n",
    "# word -> indices\n",
    "word_to_indices = {}\n",
    "for word_ex in word_mappings: \n",
    "    word_to_indices[word_ex[0]] = word_ex[1]\n",
    "    \n",
    "max_word_indices= max(indices_to_word.keys())\n",
    "print(max_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> you lied to me so many times -- </s> <s> reggie -- trust me once more -- please . </s> <s> can i really believe you this time , <person> ? </s>\n",
      "<s> you lied to me so many times -- </s> <s> reggie -- trust me once more -- please . \n",
      " can i really believe you this time , <person> ? </s>\n"
     ]
    }
   ],
   "source": [
    "# It looks like the </s> <s> denotes different speakers\n",
    "# We want to break out the first to examples and then generate the \n",
    "# third as output\n",
    "print(convert_to_words(train_set[0]))\n",
    "\n",
    "# For now we can join the first two sentences and assume that the encoder will figure it out with the </s><s>\n",
    "# Afterwards, we can think about ways to incorporate the three uttterances\n",
    "\n",
    "line = ' '.join([word_dict[ind] for ind in train_set[0]])\n",
    "line = line.split('</s> <s>')\n",
    "context = line[0] + '</s> <s>' + line[1] \n",
    "output = line[2]\n",
    "\n",
    "# So our input would be\n",
    "print(context)\n",
    "# And our output would be\n",
    "print(output)\n",
    "\n",
    "# I'll now generate matrices with that format for the rest of the data. \n",
    "# Everything will be padded with a 10003 character at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> you lied to me so many times -- </s> <s> reggie -- trust me once more -- please .\n",
      "can i really believe you this time , <person> ? </s>\n"
     ]
    }
   ],
   "source": [
    "# Will finish this up tomorow morning! :)\n",
    "pattern = [word_to_indices['</s>'], word_to_indices['<s>']]\n",
    "\n",
    "for ind in range(len(train_set[0]))[::-1]:\n",
    "    if pattern == train_set[0][ind:ind+2]:\n",
    "        break_pt = ind\n",
    "        break\n",
    "        \n",
    "context = train_set[0][:break_pt]\n",
    "output = train_set[0][break_pt+2:]\n",
    "\n",
    "print(convert_to_words(context))\n",
    "print(convert_to_words(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  6.87465274e-04,  -4.67660745e-03,   9.75181500e-03, ...,\n",
      "          6.63852702e-03,   1.36801081e-02,   1.22574021e-02],\n",
      "       [ -1.38690870e-03,  -4.40222603e-03,  -4.37635566e-03, ...,\n",
      "         -7.12008740e-03,  -8.75116355e-03,   1.79811661e-03],\n",
      "       [  1.16901258e-02,  -6.77742948e-03,  -1.96688132e-03, ...,\n",
      "          7.17334130e-03,  -8.84545310e-03,   7.13838460e-03],\n",
      "       ..., \n",
      "       [  1.82406867e-01,  -9.06357709e-01,   8.65739462e-01, ...,\n",
      "          5.20825236e-01,   8.90028319e-01,   1.24629413e+00],\n",
      "       [  1.05338908e-02,  -8.79297778e-01,  -1.47780843e+00, ...,\n",
      "          1.16881122e+00,  -3.22146225e-01,   2.51425509e+00],\n",
      "       [ -4.78275664e-01,   4.13101999e-01,   2.49392604e-01, ...,\n",
      "         -1.25812961e+00,  -1.46552975e+00,   4.08299012e-01]]), array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])]\n",
      "(10003, 300)\n"
     ]
    }
   ],
   "source": [
    "# Not sure how these embeddings work... \n",
    "print(emb)\n",
    "print(emb[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
